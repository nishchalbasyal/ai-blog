[
  {
    "objectID": "posts/Pytorch_II_Intermidiate_Intro_files/libs/Pytorch_II_Intermidiate_Intro.html",
    "href": "posts/Pytorch_II_Intermidiate_Intro_files/libs/Pytorch_II_Intermidiate_Intro.html",
    "title": "Code Explanations",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n\nclass WaterDataset(Dataset):\n  def __init__(self,csv_path):\n    super().__init__() # here it behave like a TensorDataSet\n    df = pd.read_csv(csv_path)\n    self.data = df.to_numpy()\n\n\n  def __len__(self):\n    return self.data.shape[0]\n\n  def __getitem__(self,idx):\n    features = self.data[idx,:-1]\n    label = self.data[idx,-1]\n    return np.float32(features), np.float32(label)\n\n\n\n\nimage.png\n\n\n\ndataset_train = WaterDataset(\n    \"/content/drive/MyDrive/AI/Pytorch/water_potability.csv\"\n)\n\n\nlen(dataset_train)\n\n2011\n\n\n\nfrom torch.utils.data import DataLoader\n\n\ndataloader_train = DataLoader(\n    dataset_train,\n    batch_size=50,\n    shuffle=True\n)\n\n\nfeatures,labels = next(iter(dataloader_train))\nprint(f\"Features: {features}, \\nLabels:{labels}\")\n\nFeatures: tensor([[8.2471e+00, 1.7591e+02, 9.9140e+03, 4.9745e+00, 3.2443e+02, 3.0220e+02,\n         1.1071e+01, 7.1438e+01, 3.9420e+00],\n        [7.9653e+00, 1.5154e+02, 2.5275e+04, 7.1060e+00, 3.5232e+02, 5.2769e+02,\n         1.5793e+01, 5.2268e+01, 3.3910e+00],\n        [6.3531e+00, 2.0627e+02, 1.8409e+04, 3.7238e+00, 3.4821e+02, 3.8968e+02,\n         1.3205e+01, 6.0291e+01, 2.8562e+00],\n        [3.4451e+00, 2.0793e+02, 3.3425e+04, 8.7821e+00, 3.8401e+02, 4.4179e+02,\n         1.3806e+01, 3.0285e+01, 4.1844e+00],\n        [9.9607e+00, 1.6993e+02, 1.5835e+04, 7.1439e+00, 3.0178e+02, 3.8890e+02,\n         1.3564e+01, 7.1594e+01, 3.4345e+00],\n        [8.2056e+00, 2.0467e+02, 1.7415e+04, 6.8396e+00, 2.7677e+02, 3.4654e+02,\n         1.2506e+01, 8.3917e+01, 5.1295e+00],\n        [6.1091e+00, 1.9176e+02, 2.6854e+04, 9.0646e+00, 3.1220e+02, 3.7555e+02,\n         1.5514e+01, 7.3790e+01, 4.8811e+00],\n        [7.8931e+00, 2.0143e+02, 2.0526e+04, 5.6288e+00, 2.9902e+02, 3.0388e+02,\n         1.5255e+01, 7.1542e+01, 3.3022e+00],\n        [6.5051e+00, 2.2642e+02, 1.6982e+04, 6.9385e+00, 3.1825e+02, 4.8409e+02,\n         1.8527e+01, 8.0463e+01, 2.8910e+00],\n        [6.5828e+00, 2.1918e+02, 2.1962e+04, 6.9880e+00, 3.4890e+02, 3.4121e+02,\n         1.5178e+01, 6.8982e+01, 3.6689e+00],\n        [9.9207e+00, 2.0282e+02, 9.9739e+03, 6.8822e+00, 3.3735e+02, 3.3319e+02,\n         2.3918e+01, 7.1834e+01, 4.6907e+00],\n        [8.2271e+00, 2.7435e+02, 4.0547e+04, 7.1302e+00, 2.4145e+02, 4.1767e+02,\n         9.8097e+00, 7.9397e+01, 3.6192e+00],\n        [7.3228e+00, 2.3034e+02, 2.4682e+04, 7.4256e+00, 3.2383e+02, 3.4931e+02,\n         9.4979e+00, 5.0660e+01, 3.9820e+00],\n        [8.5128e+00, 1.5767e+02, 3.3093e+04, 6.7655e+00, 3.0586e+02, 3.7762e+02,\n         1.3309e+01, 4.3019e+01, 4.0266e+00],\n        [9.0426e+00, 2.2132e+02, 1.4150e+04, 5.3259e+00, 3.6667e+02, 3.7786e+02,\n         1.3008e+01, 8.7896e+01, 4.3484e+00],\n        [5.0581e+00, 2.3857e+02, 3.4874e+04, 8.9833e+00, 3.7443e+02, 6.6973e+02,\n         1.3353e+01, 7.6522e+01, 5.1067e+00],\n        [8.6640e+00, 2.0692e+02, 2.9551e+04, 6.0303e+00, 3.3903e+02, 3.2971e+02,\n         9.1399e+00, 6.3766e+01, 3.6892e+00],\n        [9.9187e+00, 1.9918e+02, 2.1470e+04, 6.7998e+00, 3.2918e+02, 4.3051e+02,\n         1.5966e+01, 5.9292e+01, 3.3855e+00],\n        [7.4938e+00, 1.9733e+02, 2.6678e+04, 7.1984e+00, 2.6989e+02, 3.7550e+02,\n         1.3135e+01, 6.9591e+01, 3.8199e+00],\n        [5.8429e+00, 1.6830e+02, 1.9156e+04, 6.8783e+00, 3.3148e+02, 5.0676e+02,\n         1.4526e+01, 8.0424e+01, 4.1432e+00],\n        [6.3441e+00, 1.6482e+02, 1.4973e+04, 1.0707e+01, 3.1614e+02, 3.3722e+02,\n         1.9412e+01, 6.4385e+01, 3.8435e+00],\n        [8.5553e+00, 2.1666e+02, 1.8337e+04, 8.2907e+00, 3.1133e+02, 3.9094e+02,\n         1.7139e+01, 3.9777e+01, 3.6872e+00],\n        [7.2960e+00, 2.3574e+02, 3.6044e+04, 5.1962e+00, 3.7719e+02, 3.8561e+02,\n         1.7053e+01, 8.9624e+01, 4.1685e+00],\n        [7.5758e+00, 2.0388e+02, 2.0855e+04, 8.1093e+00, 3.3403e+02, 5.3231e+02,\n         1.4236e+01, 7.4639e+01, 3.1764e+00],\n        [6.0447e+00, 1.5067e+02, 1.3594e+04, 6.4562e+00, 4.0174e+02, 3.9221e+02,\n         1.9827e+01, 4.3564e+01, 4.9149e+00],\n        [6.9752e+00, 1.7542e+02, 3.5701e+04, 5.4943e+00, 2.9005e+02, 4.0106e+02,\n         1.0285e+01, 6.6421e+01, 5.2565e+00],\n        [8.9778e+00, 1.9900e+02, 2.0226e+04, 7.5695e+00, 3.5269e+02, 4.9210e+02,\n         1.9622e+01, 6.4177e+01, 3.2000e+00],\n        [6.3324e+00, 1.8684e+02, 2.3073e+04, 8.0820e+00, 3.2698e+02, 2.3391e+02,\n         9.6414e+00, 6.0940e+01, 5.1590e+00],\n        [6.8105e+00, 2.0974e+02, 3.2602e+04, 7.4228e+00, 3.4117e+02, 3.4003e+02,\n         1.6737e+01, 4.2349e+01, 4.4023e+00],\n        [9.3186e+00, 3.1734e+02, 2.4498e+04, 7.5975e+00, 3.5717e+02, 4.7651e+02,\n         1.2032e+01, 6.8600e+01, 4.6427e+00],\n        [6.9578e+00, 2.1924e+02, 2.0216e+04, 7.0541e+00, 3.0665e+02, 4.3137e+02,\n         1.7427e+01, 5.6436e+01, 4.5877e+00],\n        [6.7025e+00, 2.0732e+02, 1.7247e+04, 7.7081e+00, 3.0451e+02, 3.2927e+02,\n         1.6217e+01, 2.8879e+01, 3.4430e+00],\n        [3.7301e+00, 2.3030e+02, 1.6893e+04, 6.9972e+00, 3.2352e+02, 4.5691e+02,\n         1.0342e+01, 4.7096e+01, 4.9430e+00],\n        [5.0338e+00, 1.5532e+02, 3.4972e+04, 7.1215e+00, 3.2012e+02, 5.0064e+02,\n         1.8312e+01, 6.3193e+01, 3.2449e+00],\n        [5.6677e+00, 2.2993e+02, 1.6954e+04, 8.7743e+00, 2.9357e+02, 5.5412e+02,\n         1.4255e+01, 5.4437e+01, 3.6332e+00],\n        [7.2748e+00, 1.9512e+02, 2.1497e+04, 6.5711e+00, 3.6070e+02, 4.1837e+02,\n         1.1383e+01, 8.1236e+01, 4.2716e+00],\n        [1.2247e+01, 2.1737e+02, 1.1318e+04, 8.4652e+00, 3.7589e+02, 3.4765e+02,\n         9.7625e+00, 7.3832e+01, 3.5332e+00],\n        [7.9733e+00, 2.3750e+02, 2.3518e+04, 5.3545e+00, 2.8358e+02, 4.7889e+02,\n         1.5260e+01, 5.3671e+01, 2.8261e+00],\n        [8.6313e+00, 1.6437e+02, 1.4881e+04, 7.2783e+00, 3.5095e+02, 4.4411e+02,\n         1.6857e+01, 5.8178e+01, 3.6409e+00],\n        [6.1574e+00, 1.5584e+02, 2.5938e+04, 8.1631e+00, 2.9819e+02, 5.3329e+02,\n         1.4356e+01, 6.8121e+01, 4.7702e+00],\n        [6.6439e+00, 1.5189e+02, 1.0909e+04, 3.7496e+00, 2.4094e+02, 4.3791e+02,\n         1.5265e+01, 6.4204e+01, 3.8130e+00],\n        [8.0401e+00, 2.2486e+02, 6.8798e+03, 8.1369e+00, 4.1896e+02, 3.6096e+02,\n         1.2406e+01, 7.3218e+01, 3.9865e+00],\n        [7.8151e+00, 1.9031e+02, 2.0229e+04, 9.1869e+00, 3.3564e+02, 3.7922e+02,\n         1.4979e+01, 7.3425e+01, 3.0962e+00],\n        [6.7159e+00, 2.1806e+02, 1.7180e+04, 8.9160e+00, 3.9328e+02, 3.4900e+02,\n         1.4355e+01, 5.7247e+01, 2.4047e+00],\n        [5.4684e+00, 1.8038e+02, 1.2306e+04, 5.4466e+00, 4.1046e+02, 3.8875e+02,\n         1.2553e+01, 6.0628e+01, 4.9335e+00],\n        [8.6395e+00, 1.6861e+02, 7.0132e+03, 8.4516e+00, 3.5521e+02, 4.1979e+02,\n         1.7929e+01, 3.3642e+01, 4.1929e+00],\n        [4.8501e+00, 1.8668e+02, 3.2808e+04, 7.4963e+00, 2.9376e+02, 3.9270e+02,\n         1.0631e+01, 8.5158e+01, 3.8854e+00],\n        [4.4898e+00, 1.8825e+02, 1.4906e+04, 8.4860e+00, 3.7423e+02, 5.1859e+02,\n         1.1227e+01, 6.5183e+01, 3.7762e+00],\n        [5.2027e+00, 1.9533e+02, 2.3051e+04, 6.9596e+00, 2.4573e+02, 4.7355e+02,\n         1.1659e+01, 4.9522e+01, 3.9280e+00],\n        [7.8183e+00, 1.7922e+02, 2.7559e+04, 7.5045e+00, 3.1545e+02, 3.5910e+02,\n         1.2619e+01, 5.2377e+01, 3.3292e+00]]), \nLabels:tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n\n\n\nclass Net(nn.Module):\n  def __init__(self):\n    super(Net,self).__init__()\n    self.fc1 = nn.Linear(9,16)\n    self.fc2 =  nn.Linear(16,8)\n    self.fc3 = nn.Linear(8,1)\n\n  def forward(self,x):\n      x = nn.functional.relu(self.fc1(x))\n      x = nn.functional.relu(self.fc2(x))\n      x = nn.functional.sigmoid(self.fc3(x))\n      return x\n\nnet =  Net()\n\n\n\n\nimage.png\n\n\n\ncriterion = nn.BCELoss()\noptimizer = optim.RMSprop(net.parameters(),lr=0.01)\n\n\nepochs  = 20\nfor epoch in range(epochs):\n  total_loss = 0.0\n  for features ,labels in dataloader_train:\n    optimizer.zero_grad()\n    outputs = net(features)\n\n\n    loss = criterion(outputs,labels.view(-1,1))\n    loss.backward()\n    optimizer.step()\n\n\n    total_loss += loss.item()\n  print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader_train)}')\n\n\n\n\nEpoch [1/20], Loss: 55.33805800647271\nEpoch [2/20], Loss: 59.4013303431069\nEpoch [3/20], Loss: 59.05543238942216\nEpoch [4/20], Loss: 59.4013303431069\nEpoch [5/20], Loss: 59.74722838983303\nEpoch [6/20], Loss: 59.57427941299066\nEpoch [7/20], Loss: 59.4013303431069\nEpoch [8/20], Loss: 59.22838136626453\nEpoch [9/20], Loss: 59.4013303431069\nEpoch [10/20], Loss: 59.57427941299066\nEpoch [11/20], Loss: 59.4013303431069\nEpoch [12/20], Loss: 59.57427941299066\nEpoch [13/20], Loss: 59.4013303431069\nEpoch [14/20], Loss: 59.74722838983303\nEpoch [15/20], Loss: 59.57427941299066\nEpoch [16/20], Loss: 59.74722838983303\nEpoch [17/20], Loss: 58.88248336605909\nEpoch [18/20], Loss: 60.09312643655917\nEpoch [19/20], Loss: 59.920177366675404\nEpoch [20/20], Loss: 60.09312643655917\n\n\n\nCode Explanations\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nModel Evaluation\n\n!pip install torchmetrics\n\n\nCollecting torchmetrics\n\n  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/868.8 kB ? eta -:--:--\n     ━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.7/868.8 kB 2.0 MB/s eta 0:00:01\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 860.2/868.8 kB 12.3 MB/s eta 0:00:01\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 868.8/868.8 kB 10.1 MB/s eta 0:00:00\n\nRequirement already satisfied: numpy&gt;1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n\nRequirement already satisfied: packaging&gt;17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n\nRequirement already satisfied: torch&gt;=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n\nCollecting lightning-utilities&gt;=0.8.0 (from torchmetrics)\n\n  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n\nCollecting pretty-errors==1.2.25 (from torchmetrics)\n\n  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n\nCollecting colorama (from pretty-errors==1.2.25-&gt;torchmetrics)\n\n  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities&gt;=0.8.0-&gt;torchmetrics) (67.7.2)\n\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities&gt;=0.8.0-&gt;torchmetrics) (4.11.0)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;torchmetrics) (3.14.0)\n\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;torchmetrics) (1.12)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;torchmetrics) (3.3)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;torchmetrics) (3.1.4)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;torchmetrics) (2023.6.0)\n\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\nCollecting nvidia-nccl-cu12==2.19.3 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;torchmetrics) (2.2.0)\n\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch&gt;=1.10.0-&gt;torchmetrics)\n\n  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=1.10.0-&gt;torchmetrics) (2.1.5)\n\nRequirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=1.10.0-&gt;torchmetrics) (1.3.0)\n\nInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n\nSuccessfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 torchmetrics-1.4.0\n\n\n\n\n\nfrom torchmetrics import Accuracy\n\n\nacc = Accuracy(task=\"binary\")\nnet.eval()\nwith torch.no_grad():\n  for features,labels in dataloader_train:\n    outputs = net(features)\n    preds = (outputs&gt;=0.5).float()\n    acc(preds,labels.view(-1,1))\ntest_accuracy = acc.compute()\nprint(f\"Test accuracy:{test_accuracy}\")\n\nTest accuracy:0.40328195691108704\n\n\nExplanation \nVanishing and Exploding Gradients\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nWeights Initializations \n\nlayer =  nn.Linear(8,1)\nprint(layer.weight)\n\nParameter containing:\ntensor([[-0.0200,  0.1698,  0.1512,  0.3476,  0.0478, -0.0884, -0.2626,  0.2111]],\n       requires_grad=True)\n\n\n\n# weights initialization using He/Kaiming Initialization\nimport torch.nn.init as init\n\ninit.kaiming_uniform_(layer.weight)\nprint(layer.weight.detach().numpy())\n\n[[ 0.07571412 -0.857833   -0.7581954  -0.19864778  0.59920317  0.4359296\n  -0.38736093 -0.329777  ]]\n\n\n\n# import torch\n# import torch.nn.functional as F\n# import math\n# input_size=1200\n# hidden_size=4000\n# w=torch.randn(hidden_size,input_size)*math.sqrt(2/input_size)\n# x=torch.randn(input_size,1)\n# y=w@F.relu(x)\n# x.var(),y.var()\n\n\nclass Net(nn.Module):\n  def __init__(self):\n    super(Net,self).__init__()\n    self.fc1 = nn.Linear(9,16)\n    self.fc2 =  nn.Linear(16,8)\n    self.fc3 = nn.Linear(8,1)\n    init.kaiming_uniform_(self.fc1.weight)\n    init.kaiming_uniform_(self.fc2.weight)\n    init.kaiming_uniform_(\n        self.fc3.weight,\n        nonlinearity=\"sigmoid\",\n    )\n\n\n  def forward(self,x):\n      x = nn.functional.relu(self.fc1(x))\n      x = nn.functional.relu(self.fc2(x))\n      x = nn.functional.sigmoid(self.fc3(x))\n      return x\n\nnet =  Net()\n\nepochs  = 20\nfor epoch in range(epochs):\n  total_loss = 0.0\n  for features ,labels in dataloader_train:\n    optimizer.zero_grad()\n    outputs = net(features)\n\n\n    loss = criterion(outputs,labels.view(-1,1))\n    loss.backward()\n    optimizer.step()\n\n\n    total_loss += loss.item()\n  print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader_train)}')\n\nacc = Accuracy(task=\"binary\")\nnet.eval()\nwith torch.no_grad():\n  for features,labels in dataloader_train:\n    outputs = net(features)\n    preds = (outputs&gt;=0.5).float()\n    acc(preds,labels.view(-1,1))\ntest_accuracy = acc.compute()\nprint(f\"Test accuracy:{test_accuracy}\")\n\nEpoch [1/20], Loss: 39.977170153361996\nEpoch [2/20], Loss: 40.841915130615234\nEpoch [3/20], Loss: 39.45832312979349\nEpoch [4/20], Loss: 39.63127212989621\nEpoch [5/20], Loss: 39.45832312979349\nEpoch [6/20], Loss: 39.80422112999893\nEpoch [7/20], Loss: 40.32306810704673\nEpoch [8/20], Loss: 40.15011913020437\nEpoch [9/20], Loss: 40.32306810704673\nEpoch [10/20], Loss: 40.15011913020437\nEpoch [11/20], Loss: 39.63127212989621\nEpoch [12/20], Loss: 40.15011913020437\nEpoch [13/20], Loss: 40.15011913020437\nEpoch [14/20], Loss: 39.97717019988269\nEpoch [15/20], Loss: 40.32306810704673\nEpoch [16/20], Loss: 40.32306810704673\nEpoch [17/20], Loss: 40.15011917672506\nEpoch [18/20], Loss: 39.977170153361996\nEpoch [19/20], Loss: 40.32306810704673\nEpoch [20/20], Loss: 40.15011913020437\nTest accuracy:0.5967180728912354\n\n\n\n\n\nimage.png\n\n\n\n\nBatch Normalization\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\nclass Net(nn.Module):\n  def __init__(self):\n    super(Net,self).__init__()\n    self.fc1 = nn.Linear(9,16)\n    self.bn1 = nn.BatchNorm1d(16)\n    self.fc2 =  nn.Linear(16,8)\n    self.fc3 = nn.Linear(8,1)\n\n\n    init.kaiming_uniform_(self.fc1.weight)\n    init.kaiming_uniform_(self.fc2.weight)\n    init.kaiming_uniform_(\n        self.fc3.weight,\n        nonlinearity=\"sigmoid\",\n    )\n\n\n  def forward(self,x):\n      x = self.fc1(x)\n      x = self.bn1(x)\n      x = nn.functional.elu(x)\n      x = nn.functional.elu(self.fc2(x))\n      x = nn.functional.sigmoid(self.fc3(x))\n      return x\n\nnet =  Net()\n\nepochs  = 20\nfor epoch in range(epochs):\n  total_loss = 0.0\n  for features ,labels in dataloader_train:\n    optimizer.zero_grad()\n    outputs = net(features)\n\n\n    loss = criterion(outputs,labels.view(-1,1))\n    loss.backward()\n    optimizer.step()\n\n\n    total_loss += loss.item()\n  print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader_train)}')\n\nacc = Accuracy(task=\"binary\")\nnet.eval()\nwith torch.no_grad():\n  for features,labels in dataloader_train:\n    outputs = net(features)\n    preds = (outputs&gt;=0.5).float()\n    acc(preds,labels.view(-1,1))\ntest_accuracy = acc.compute()\nprint(f\"Test accuracy:{test_accuracy}\")\n\nEpoch [1/20], Loss: 0.676278037268941\nEpoch [2/20], Loss: 0.6801634590800215\nEpoch [3/20], Loss: 0.6774980760202175\nEpoch [4/20], Loss: 0.6785745780642439\nEpoch [5/20], Loss: 0.6793669302289079\nEpoch [6/20], Loss: 0.6797820867561712\nEpoch [7/20], Loss: 0.6769404280476454\nEpoch [8/20], Loss: 0.6800835961248817\nEpoch [9/20], Loss: 0.6798731190402333\nEpoch [10/20], Loss: 0.6800505766054479\nEpoch [11/20], Loss: 0.6773186674932155\nEpoch [12/20], Loss: 0.6798041811803492\nEpoch [13/20], Loss: 0.6802630497188102\nEpoch [14/20], Loss: 0.6796207835034627\nEpoch [15/20], Loss: 0.6793888763683599\nEpoch [16/20], Loss: 0.6800950373091349\nEpoch [17/20], Loss: 0.6793506639759715\nEpoch [18/20], Loss: 0.6784993773553429\nEpoch [19/20], Loss: 0.6791951525502089\nEpoch [20/20], Loss: 0.6790863086537617\nTest accuracy:0.5967180728912354"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ai-blog",
    "section": "",
    "text": "Loss Function\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Explanations\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html",
    "href": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html",
    "title": "Create the dataset and the dtaloader",
    "section": "",
    "text": "image.png\nimport torch.nn as nn\nimport torch\n## Create input_tensor with three features\ninput_tensor = torch.tensor(\n    [[0.3471,0.4547,-0.2356]]\n)\n# Define our First linear layer\nlinear_layer = nn.Linear(in_features=3, out_features=2)\n# Pass input through linear layer\noutput = linear_layer(input_tensor)\nprint(output)\n\ntensor([[-0.1275,  0.0318]], grad_fn=&lt;AddmmBackward0&gt;)\nlinear_layer.weight\n\nParameter containing:\ntensor([[-0.0425, -0.1467, -0.2155],\n        [-0.0660, -0.1149, -0.2340]], requires_grad=True)\nlinear_layer.bias\n\nParameter containing:\ntensor([-0.0968,  0.0519], requires_grad=True)\nmodel = nn.Sequential(\n    nn.Linear(10,18),\n    nn.Linear(18,20),\n    nn.Linear(20,5)\n)\ninput_tensor = torch.tensor([[6.0]])\nsigmoid = nn.Sigmoid()\noutput =  sigmoid(input_tensor)\noutput\n\ntensor([[0.9975]])\nmodel = nn.Sequential(\n    nn.Linear(6,4), # First Linear layer\n    nn.Linear(4,1), # Seconf linear layer\n    nn.Softmax(dim=-1)\n)\n# output = model(input_tensor)\n# print(output)\n# For Binary Class Prediction\n\nmodel = nn.Sequential(\n    nn.Linear(8,1),\n    nn.Sigmoid()\n)\n\n# model.description()"
  },
  {
    "objectID": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html#sample-working-code-of-dataloader-and-tensordataset",
    "href": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html#sample-working-code-of-dataloader-and-tensordataset",
    "title": "Create the dataset and the dtaloader",
    "section": "Sample Working Code of DataLoader and TensorDataSet",
    "text": "Sample Working Code of DataLoader and TensorDataSet\n# Load the different columns into two PyTorch tensors\nfeatures = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()\ntarget = torch.tensor(dataframe['Potability'].to_numpy()).float()\n\n# Create a dataset from the two generated tensors\ndataset = TensorDataset(features, target)\n\n# Create a dataloader using the above dataset\ndataloader = DataLoader(dataset, shuffle=True, batch_size=2)\nx, y = next(iter(dataloader))\n\n# Create a model using the nn.Sequential API\nmodel = nn.Sequential(nn.Linear(4,1),nn.Linear(1,1))\noutput = model(features)\nprint(output)\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n# Set the model to evaluation mode\nmodel.eval()\nvalidation_loss = 0.0\n\nwith torch.no_grad():\n  \n  for data in validationloader:\n    \n      outputs = model(data[0])\n      loss = criterion(outputs, data[1])\n      \n      # Sum the current loss to the validation_loss variable\n      validation_loss += loss.item()\n      \n# Calculate the mean loss value\nvalidation_loss_epoch = validation_loss/len(validationloader)\nprint(validation_loss_epoch)\n\n# Set the model back to training mode\nmodel.train()\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html#dropout",
    "href": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html#dropout",
    "title": "Create the dataset and the dtaloader",
    "section": "Dropout",
    "text": "Dropout\n\n\n\nimage.png\n\n\n# Using the same model, set the dropout probability to 0.8\nmodel = nn.Sequential(\n    nn.Linear(3072,16),\n    nn.ReLU(),\n    nn.Dropout(p=0.8)\n)\nmodel(input_tensor)"
  },
  {
    "objectID": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html#weight-decay",
    "href": "posts/Pytorch_ANN_Begiiner_NoteBook_files/Pytorch_ANN_Begiiner_NoteBook.html#weight-decay",
    "title": "Create the dataset and the dtaloader",
    "section": "Weight Decay",
    "text": "Weight Decay\n\n\n\nimage.png"
  }
]